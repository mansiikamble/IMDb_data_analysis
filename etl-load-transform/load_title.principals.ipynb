{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7baf2afc-58f2-4ac8-9dfc-e74fe3bf4a15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Libraries management\n",
    "import dlt\n",
    "# from pyspark import pipelines as dp\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21b1bc39-1729-4fa6-9e22-ce9c07f43aa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"USE CATALOG `workspace`\")\n",
    "spark.sql(\"USE SCHEMA `imdb_data_analysis`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec50d31b-4460-4f14-9183-26379fbb77bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Environment Setup\n",
    "catalog = \"workspace\"\n",
    "schema = \"imdb_data_analysis\"\n",
    "volume = \"datastore\"\n",
    "file_name = \"title.principals\"\n",
    "\n",
    "# Paths\n",
    "path_volume = f\"/Volumes/{catalog}/{schema}/{volume}/{file_name}\"\n",
    "volume_path = f\"{path_volume}/{file_name}.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ac827c0-3c00-4789-8070-9b4fc161ecbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"bronze_imdb_title_principals\",\n",
    "    comment=\"Bronze layer: Raw IMDB mapping Titles to Crew and Job Roles data ingested from TSV files in Unity Catalog Volume\"\n",
    ")\n",
    "def bronze_imdb_title_principals():\n",
    "    return (\n",
    "        spark.readStream\n",
    "            .format(\"cloudFiles\")\n",
    "            .option(\"cloudFiles.format\", \"csv\")\n",
    "            .option(\"delimiter\", \"\\t\")\n",
    "            .option(\"header\", \"true\")\n",
    "            .option(\"cloudFiles.schemaLocation\", path_volume)\n",
    "            .load(path_volume)\n",
    "            .withColumn(\"bronze_load_timestamp\", current_timestamp())\n",
    "            .withColumn(\"bronze_load_date\", current_date())\n",
    "            .withColumn(\"source_system\", lit(\"IMDB_TSV\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7ec9edc-0b9a-4ffc-823a-bcdfd39c57b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"silver_imdb_title_principals\",\n",
    "    comment=\"Silver layer: IMDB Titles to Crew Mappings with job roles data ingested from Bronze Layer\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"tconst_check\", \"tconst IS NOT NULL\")\n",
    "@dlt.expect_or_drop(\"nconst_check\", \"nconst IS NOT NULL\")\n",
    "@dlt.expect(\"ordering_check\", \"CAST(ordering AS INT) > 0\")\n",
    "def silver_imdb_title_principals():\n",
    "    df = dlt.read_stream(\"bronze_imdb_title_principals\")\n",
    "    df = df.withColumn(\"ordering\", col(\"ordering\").cast(\"int\"))\n",
    "    df = df.withColumn(\"characters\", regexp_extract(col(\"characters\"), '\\\\[\"(.+)\"\\\\]', 1))\n",
    "    df = df.withColumn(\"characters\", when(col(\"characters\") == \"\", \"Unknown\").otherwise(col(\"characters\")))\n",
    "\n",
    "    df = df.select(\"tconst\", \"ordering\", \"nconst\", \"category\", \"characters\")\n",
    "    df = df.withColumn(\"silver_load_timestamp\", current_timestamp())\n",
    "    df = df.withColumn(\"source_system\", lit(\"bronze_imdb_title_principals\"))    \n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "load_title.principals",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
