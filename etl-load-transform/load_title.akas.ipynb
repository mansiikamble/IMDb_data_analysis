{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7baf2afc-58f2-4ac8-9dfc-e74fe3bf4a15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Libraries management\n",
    "import dlt\n",
    "# from pyspark import pipelines as dp\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21b1bc39-1729-4fa6-9e22-ce9c07f43aa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"USE CATALOG `workspace`\")\n",
    "spark.sql(\"USE SCHEMA `imdb_data_analysis`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec50d31b-4460-4f14-9183-26379fbb77bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Environment Setup\n",
    "catalog = \"workspace\"\n",
    "schema = \"imdb_data_analysis\"\n",
    "volume = \"datastore\"\n",
    "file_name = \"title.akas\"\n",
    "\n",
    "# Paths\n",
    "path_volume = f\"/Volumes/{catalog}/{schema}/{volume}/{file_name}\"\n",
    "volume_path = f\"{path_volume}/{file_name}.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ac827c0-3c00-4789-8070-9b4fc161ecbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"bronze_imdb_title_akas\",\n",
    "    comment=\"Bronze layer: Raw IMDB Titles & its region, language, channels ingested from TSV files in Unity Catalog Volume\"\n",
    ")\n",
    "def bronze_imdb_title_akas():\n",
    "    return (\n",
    "        spark.readStream\n",
    "            .format(\"cloudFiles\")\n",
    "            .option(\"cloudFiles.format\", \"csv\")\n",
    "            .option(\"delimiter\", \"\\t\")\n",
    "            .option(\"header\", \"true\")\n",
    "            .option(\"cloudFiles.schemaLocation\", path_volume)\n",
    "            .load(path_volume)\n",
    "            .withColumn(\"bronze_load_timestamp\", current_timestamp())\n",
    "            .withColumn(\"bronze_load_date\", current_date())\n",
    "            .withColumn(\"source_system\", lit(\"IMDB_TSV\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c97d254-7f60-4af3-a82e-9f17fbf5e6bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"silver_imdb_title_akas\",\n",
    "    comment=\"Silver layer: IMDB Titles & its region, language, channels data streamed from Bronze layer, clean and transform\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"titleId_check\", \"titleId IS NOT NULL\")\n",
    "@dlt.expect_or_drop(\"ordering_check\", \"CAST(ordering AS INT) > 0\")\n",
    "def silver_imdb_title_akas():\n",
    "    df = dlt.read_stream(\"bronze_imdb_title_akas\")\n",
    "    df = df.withColumn(\"ordering\", df.ordering.cast(IntegerType()))\n",
    "    df = df.withColumn(\"region\", when(col(\"region\") == \"\\\\N\", \"Unknown\").otherwise(col(\"region\")))\n",
    "    df = df.withColumn(\"region\", when(col(\"region\").isNull(), \"Unknown\").otherwise(col(\"region\")))\n",
    "    df = df.withColumn(\"language\", when(col(\"language\") == \"\\\\N\", \"Unknown\").otherwise(col(\"language\")))\n",
    "    df = df.withColumn(\"language\", when(col(\"language\").isNull(), \"Unknown\").otherwise(col(\"language\")))\n",
    "    df = df.withColumn(\"types\", when(col(\"types\") == \"\\\\N\", \"Unknown\").otherwise(col(\"types\")))\n",
    "    df = df.withColumn(\"types\", when(col(\"types\").isNull(), \"Unknown\").otherwise(col(\"types\")))\n",
    "    df = df.withColumn(\"isOriginalTitle\", when(col(\"isOriginalTitle\").isNull(), \"-1\").otherwise(col(\"isOriginalTitle\")).cast(\"int\"))\n",
    "    df = df.withColumn(\"silver_load_timestamp\", current_timestamp())\n",
    "    df = df.withColumn(\"source_system\", lit(\"silver_imdb_title_akas\"))    \n",
    "    return df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "load_title.akas",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
