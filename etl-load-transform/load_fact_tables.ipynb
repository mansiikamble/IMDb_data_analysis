{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e02b8c8-0755-463d-91b4-229e034ba039",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Libraries management\n",
    "import dlt\n",
    "# from pyspark import pipelines as dp\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7bbc93dc-7f28-45ca-b2ce-896fec549689",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"USE CATALOG `workspace`\")\n",
    "spark.sql(\"USE SCHEMA `imdb_data_analysis`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ff9e3e4-c0dd-492b-8355-2b6b586ea4d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load FACT_REGIONAL_RELEASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "482b8f5e-7eab-46b5-8db5-fac695f173db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GOLD LAYER: fact_regional_release\n",
    "# =============================================================================\n",
    "# Description: Fact table for title releases across regions and languages\n",
    "# Source: silver_imdb_title_akas + dim_title + dim_region + dim_language\n",
    "# Grain: One row per title-region-language-ordering combination\n",
    "# =============================================================================\n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    col, lit, current_timestamp, upper, lower, trim, coalesce, monotonically_increasing_id\n",
    ")\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"fact_regional_release\",\n",
    "    comment=\"Gold layer: Fact table for title releases across regions and languages\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"layer\": \"gold\",\n",
    "        \"domain\": \"imdb\"\n",
    "    }\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_title_key\", \"title_key IS NOT NULL\")\n",
    "def gold_fact_regional_release():\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Read from Silver layer\n",
    "    # -------------------------------------------------------------------------\n",
    "    df = spark.read.table(\"LIVE.silver_imdb_title_akas\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Read dimension tables for key lookups\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    # dim_title lookup\n",
    "    df_title = spark.read.table(\"LIVE.dim_title\").select(\n",
    "        col(\"tconst\").alias(\"title_tconst\"),\n",
    "        col(\"title_key\")\n",
    "    )\n",
    "    \n",
    "    # dim_region lookup\n",
    "    df_region = spark.read.table(\"LIVE.dim_region\").select(\n",
    "        col(\"region_code\").alias(\"region_lookup_code\"),\n",
    "        col(\"region_key\")\n",
    "    )\n",
    "    \n",
    "    # dim_language lookup\n",
    "    df_language = spark.read.table(\"LIVE.dim_language\").select(\n",
    "        col(\"language_code\").alias(\"language_lookup_code\"),\n",
    "        col(\"language_key\")\n",
    "    )\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Prepare join keys (normalize case)\n",
    "    # -------------------------------------------------------------------------\n",
    "    df = df.withColumn(\"region_upper\", upper(trim(col(\"region\"))))\n",
    "    df = df.withColumn(\"language_lower\", lower(trim(col(\"language\"))))\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Join with dim_title\n",
    "    # -------------------------------------------------------------------------\n",
    "    df = df.join(\n",
    "        df_title,\n",
    "        df[\"titleId\"] == df_title[\"title_tconst\"],\n",
    "        \"inner\"\n",
    "    ).drop(\"title_tconst\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Join with dim_region (left join - keep records even if region not found)\n",
    "    # -------------------------------------------------------------------------\n",
    "    df = df.join(\n",
    "        df_region,\n",
    "        df[\"region_upper\"] == df_region[\"region_lookup_code\"],\n",
    "        \"left\"\n",
    "    ).drop(\"region_lookup_code\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Join with dim_language (left join - keep records even if language not found)\n",
    "    # -------------------------------------------------------------------------\n",
    "    df = df.join(\n",
    "        df_language,\n",
    "        df[\"language_lower\"] == df_language[\"language_lookup_code\"],\n",
    "        \"left\"\n",
    "    ).drop(\"language_lookup_code\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Handle NULL keys - replace with -1 (Unknown member)\n",
    "    # -------------------------------------------------------------------------\n",
    "    df = df.withColumn(\n",
    "        \"region_key\",\n",
    "        coalesce(col(\"region_key\"), lit(-1))\n",
    "    )\n",
    "    \n",
    "    df = df.withColumn(\n",
    "        \"language_key\",\n",
    "        coalesce(col(\"language_key\"), lit(-1))\n",
    "    )\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Rename columns\n",
    "    # -------------------------------------------------------------------------\n",
    "    df = df.withColumnRenamed(\"title\", \"localized_title\")\n",
    "    df = df.withColumnRenamed(\"types\", \"release_types\")\n",
    "    df = df.withColumnRenamed(\"isOriginalTitle\", \"is_original_title\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Generate surrogate key\n",
    "    # -------------------------------------------------------------------------\n",
    "    df = df.withColumn(\n",
    "        \"regional_release_key\",\n",
    "        monotonically_increasing_id() + 1\n",
    "    )\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Add metadata and audit columns\n",
    "    # -------------------------------------------------------------------------\n",
    "    df = df.withColumn(\"source_system\", lit(\"silver_imdb_title_akas\"))\n",
    "    df = df.withColumn(\"etl_load_timestamp\", current_timestamp())\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Select final columns in schema order\n",
    "    # -------------------------------------------------------------------------\n",
    "    df_final = df.select(\n",
    "        \"regional_release_key\",\n",
    "        \"title_key\",\n",
    "        \"region_key\",\n",
    "        \"language_key\",\n",
    "        \"ordering\",\n",
    "        \"localized_title\",\n",
    "        \"release_types\",\n",
    "        \"is_original_title\",\n",
    "        \"source_system\",\n",
    "        \"etl_load_timestamp\"\n",
    "    )\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db7272e4-2895-41be-ba16-141ef705d7dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load FACT_TITLE_RATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9409da83-2021-4380-a0dd-d995f471934a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GOLD LAYER: fact_title_ratings\n",
    "# =============================================================================\n",
    "# Description: Fact table for title ratings and vote counts\n",
    "# Source: silver_imdb_title_ratings + dim_title\n",
    "# Grain: One row per rated title (tconst)\n",
    "# =============================================================================\n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    col, lit, current_timestamp, monotonically_increasing_id\n",
    ")\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"fact_title_ratings\",\n",
    "    comment=\"Gold layer: Fact table for title ratings and vote counts\",\n",
    "    table_properties={\n",
    "        \"quality\": \"gold\",\n",
    "        \"layer\": \"gold\",\n",
    "        \"domain\": \"imdb\"\n",
    "    }\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_title_key\", \"title_key IS NOT NULL\")\n",
    "@dlt.expect_or_drop(\"valid_rating\", \"rating IS NOT NULL\")\n",
    "@dlt.expect_or_drop(\"valid_vote_count\", \"vote_count IS NOT NULL\")\n",
    "def gold_fact_title_ratings():\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Read from Silver layer\n",
    "    # -------------------------------------------------------------------------\n",
    "    df = spark.read.table(\"LIVE.silver_imdb_title_ratings\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Read dim_title for key lookup\n",
    "    # -------------------------------------------------------------------------\n",
    "    df_title = spark.read.table(\"LIVE.dim_title\").select(\n",
    "        col(\"tconst\").alias(\"title_tconst\"),\n",
    "        col(\"title_key\")\n",
    "    )\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Join with dim_title\n",
    "    # -------------------------------------------------------------------------\n",
    "    df = df.join(\n",
    "        df_title,\n",
    "        df[\"tconst\"] == df_title[\"title_tconst\"],\n",
    "        \"inner\"\n",
    "    ).drop(\"title_tconst\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Generate surrogate key (starting from 1)\n",
    "    # -------------------------------------------------------------------------\n",
    "    df = df.withColumn(\n",
    "        \"title_rating_key\",\n",
    "        monotonically_increasing_id() + 1\n",
    "    )\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Add metadata and audit columns\n",
    "    # -------------------------------------------------------------------------\n",
    "    df = df.withColumn(\"source_system\", lit(\"silver_imdb_title_ratings\"))\n",
    "    df = df.withColumn(\"etl_load_timestamp\", current_timestamp())\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Select final columns in schema order\n",
    "    # -------------------------------------------------------------------------\n",
    "    df_final = df.select(\n",
    "        \"title_rating_key\",\n",
    "        \"title_key\",\n",
    "        \"rating\",\n",
    "        \"vote_count\",\n",
    "        \"source_system\",\n",
    "        \"etl_load_timestamp\"\n",
    "    )\n",
    "    \n",
    "    return df_final"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "load_fact_tables",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
