{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ae1bc89-ae71-44a7-9d83-cc29031971cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-labs-dqx --quiet\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fe5fff0-9856-4930-ada9-3a23b5301f0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.labs.dqx.profiler.profiler import DQProfiler\n",
    "from databricks.labs.dqx.profiler.generator import DQGenerator\n",
    "from databricks.labs.dqx.engine import DQEngine\n",
    "from databricks.labs.dqx.config import WorkspaceFileChecksStorageConfig\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from pyspark.sql import SparkSession\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Initialize\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "ws = WorkspaceClient()\n",
    "profiler = DQProfiler(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eac1ecbe-847c-4ddb-aa1f-aa3c7eae302a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Base path for IMDB data in Unity Catalog Volume\n",
    "BASE_PATH = \"/Volumes/workspace/imdb_data_analysis/datastore\"\n",
    "\n",
    "# Define all 7 IMDB file paths\n",
    "file_paths = {\n",
    "    \"title_basics\": f\"{BASE_PATH}/title.basics.tsv\",\n",
    "    \"title_ratings\": f\"{BASE_PATH}/title.ratings.tsv\",\n",
    "    \"name_basics\": f\"{BASE_PATH}/name.basics.tsv\",\n",
    "    \"title_principals\": f\"{BASE_PATH}/title.principals.tsv\",\n",
    "    \"title_crew\": f\"{BASE_PATH}/title.crew.tsv\",\n",
    "    \"title_episode\": f\"{BASE_PATH}/title.episode.tsv\",\n",
    "    \"title_akas\": f\"{BASE_PATH}/title.akas.tsv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33b66a4e-479e-425a-a14c-33ea8467e351",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load title.basics\n",
    "df_title_basics = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \"\\t\") \\\n",
    "    .option(\"quote\", \"\") \\\n",
    "    .option(\"escape\", \"\") \\\n",
    "    .option(\"nullValue\", \"\\\\N\") \\\n",
    "    .csv(file_paths[\"title_basics\"])\n",
    "\n",
    "# Load title.ratings\n",
    "df_title_ratings = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \"\\t\") \\\n",
    "    .option(\"quote\", \"\") \\\n",
    "    .option(\"escape\", \"\") \\\n",
    "    .option(\"nullValue\", \"\\\\N\") \\\n",
    "    .csv(file_paths[\"title_ratings\"])\n",
    "\n",
    "# Load name.basics\n",
    "df_name_basics = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \"\\t\") \\\n",
    "    .option(\"quote\", \"\") \\\n",
    "    .option(\"escape\", \"\") \\\n",
    "    .option(\"nullValue\", \"\\\\N\") \\\n",
    "    .csv(file_paths[\"name_basics\"])\n",
    "\n",
    "# Load title.principals\n",
    "df_title_principals = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \"\\t\") \\\n",
    "    .option(\"quote\", \"\") \\\n",
    "    .option(\"escape\", \"\") \\\n",
    "    .option(\"nullValue\", \"\\\\N\") \\\n",
    "    .csv(file_paths[\"title_principals\"])\n",
    "\n",
    "# Load title.crew\n",
    "df_title_crew = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \"\\t\") \\\n",
    "    .option(\"quote\", \"\") \\\n",
    "    .option(\"escape\", \"\") \\\n",
    "    .option(\"nullValue\", \"\\\\N\") \\\n",
    "    .csv(file_paths[\"title_crew\"])\n",
    "\n",
    "# Load title.episode\n",
    "df_title_episode = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \"\\t\") \\\n",
    "    .option(\"quote\", \"\") \\\n",
    "    .option(\"escape\", \"\") \\\n",
    "    .option(\"nullValue\", \"\\\\N\") \\\n",
    "    .csv(file_paths[\"title_episode\"])\n",
    "\n",
    "# Load title.akas\n",
    "df_title_akas = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \"\\t\") \\\n",
    "    .option(\"quote\", \"\") \\\n",
    "    .option(\"escape\", \"\") \\\n",
    "    .option(\"nullValue\", \"\\\\N\") \\\n",
    "    .csv(file_paths[\"title_akas\"])\n",
    "\n",
    "# Store in dictionary for easier iteration\n",
    "datasets = {\n",
    "    \"title_basics\": df_title_basics,\n",
    "    \"title_ratings\": df_title_ratings,\n",
    "    \"name_basics\": df_name_basics,\n",
    "    \"title_principals\": df_title_principals,\n",
    "    \"title_crew\": df_title_crew,\n",
    "    \"title_episode\": df_title_episode,\n",
    "    \"title_akas\": df_title_akas\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3be82f3-1b2d-428e-867b-1db24da05b0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Profiling configurations for each dataset (full data, no sampling)\n",
    "profiling_configs = {\n",
    "    \"title_basics\": {\n",
    "        \"options\": {\n",
    "            \"sample_fraction\": None,\n",
    "            \"limit\": None,\n",
    "            \"round\": True,\n",
    "            \"max_in_count\": 20,\n",
    "            \"distinct_ratio\": 0.001,\n",
    "            \"max_null_ratio\": 0.15,\n",
    "            \"remove_outliers\": True,\n",
    "            \"outlier_columns\": [\"runtimeMinutes\", \"startYear\"],\n",
    "            \"num_sigmas\": 3,\n",
    "            \"trim_strings\": True,\n",
    "            \"max_empty_ratio\": 0.01\n",
    "        },\n",
    "        \"columns\": [\"tconst\", \"titleType\", \"primaryTitle\", \"isAdult\", \"startYear\", \"endYear\", \"runtimeMinutes\", \"genres\"]\n",
    "    },\n",
    "    \n",
    "    \"title_ratings\": {\n",
    "        \"options\": {\n",
    "            \"sample_fraction\": None,\n",
    "            \"limit\": None,\n",
    "            \"round\": True,\n",
    "            \"max_in_count\": 100,\n",
    "            \"distinct_ratio\": 0.01,\n",
    "            \"max_null_ratio\": 0.0,\n",
    "            \"remove_outliers\": True,\n",
    "            \"outlier_columns\": [\"numVotes\"],\n",
    "            \"num_sigmas\": 3,\n",
    "            \"trim_strings\": False,\n",
    "            \"max_empty_ratio\": 0.0\n",
    "        },\n",
    "        \"columns\": [\"tconst\", \"averageRating\", \"numVotes\"]\n",
    "    },\n",
    "    \n",
    "    \"name_basics\": {\n",
    "        \"options\": {\n",
    "            \"sample_fraction\": None,\n",
    "            \"limit\": None,\n",
    "            \"round\": True,\n",
    "            \"max_in_count\": 50,\n",
    "            \"distinct_ratio\": 0.001,\n",
    "            \"max_null_ratio\": 0.25,\n",
    "            \"remove_outliers\": True,\n",
    "            \"outlier_columns\": [\"birthYear\", \"deathYear\"],\n",
    "            \"num_sigmas\": 3,\n",
    "            \"trim_strings\": True,\n",
    "            \"max_empty_ratio\": 0.01\n",
    "        },\n",
    "        \"columns\": [\"nconst\", \"primaryName\", \"birthYear\", \"deathYear\", \"primaryProfession\", \"knownForTitles\"]\n",
    "    },\n",
    "    \n",
    "    \"title_principals\": {\n",
    "        \"options\": {\n",
    "            \"sample_fraction\": None,\n",
    "            \"limit\": None,\n",
    "            \"round\": True,\n",
    "            \"max_in_count\": 15,\n",
    "            \"distinct_ratio\": 0.0001,\n",
    "            \"max_null_ratio\": 0.5,\n",
    "            \"remove_outliers\": True,\n",
    "            \"outlier_columns\": [\"ordering\"],\n",
    "            \"num_sigmas\": 3,\n",
    "            \"trim_strings\": True,\n",
    "            \"max_empty_ratio\": 0.3\n",
    "        },\n",
    "        \"columns\": [\"tconst\", \"ordering\", \"nconst\", \"category\", \"job\", \"characters\"]\n",
    "    },\n",
    "    \n",
    "    \"title_crew\": {\n",
    "        \"options\": {\n",
    "            \"sample_fraction\": None,\n",
    "            \"limit\": None,\n",
    "            \"round\": True,\n",
    "            \"max_in_count\": 20,\n",
    "            \"distinct_ratio\": 0.01,\n",
    "            \"max_null_ratio\": 0.4,\n",
    "            \"remove_outliers\": False,\n",
    "            \"num_sigmas\": 3,\n",
    "            \"trim_strings\": True,\n",
    "            \"max_empty_ratio\": 0.35\n",
    "        },\n",
    "        \"columns\": [\"tconst\", \"directors\", \"writers\"]\n",
    "    },\n",
    "    \n",
    "    \"title_episode\": {\n",
    "        \"options\": {\n",
    "            \"sample_fraction\": None,\n",
    "            \"limit\": None,\n",
    "            \"round\": True,\n",
    "            \"max_in_count\": 30,\n",
    "            \"distinct_ratio\": 0.001,\n",
    "            \"max_null_ratio\": 0.3,\n",
    "            \"remove_outliers\": True,\n",
    "            \"outlier_columns\": [\"seasonNumber\", \"episodeNumber\"],\n",
    "            \"num_sigmas\": 3,\n",
    "            \"trim_strings\": True,\n",
    "            \"max_empty_ratio\": 0.25\n",
    "        },\n",
    "        \"columns\": [\"tconst\", \"parentTconst\", \"seasonNumber\", \"episodeNumber\"]\n",
    "    },\n",
    "    \n",
    "    \"title_akas\": {\n",
    "        \"options\": {\n",
    "            \"sample_fraction\": None,\n",
    "            \"limit\": None,\n",
    "            \"round\": True,\n",
    "            \"max_in_count\": 100,\n",
    "            \"distinct_ratio\": 0.0001,\n",
    "            \"max_null_ratio\": 0.5,\n",
    "            \"remove_outliers\": False,\n",
    "            \"num_sigmas\": 3,\n",
    "            \"trim_strings\": True,\n",
    "            \"max_empty_ratio\": 0.4\n",
    "        },\n",
    "        \"columns\": [\"titleId\", \"ordering\", \"title\", \"region\", \"language\", \"types\", \"attributes\", \"isOriginalTitle\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3926aaa9-1f39-4d87-9a8e-eef2353757e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Profile all datasets with DQX\n",
    "all_profiles = {}\n",
    "all_summary_stats = {}\n",
    "profiling_times = {}\n",
    "\n",
    "for dataset_name, df in datasets.items():\n",
    "    config = profiling_configs[dataset_name]\n",
    "    \n",
    "    # Select only specified columns\n",
    "    df_filtered = df.select(config['columns'])\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Profile dataset\n",
    "    summary_stats, profiles = profiler.profile(\n",
    "        df=df_filtered,\n",
    "        options=config['options']\n",
    "    )\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Store results\n",
    "    all_summary_stats[dataset_name] = summary_stats\n",
    "    all_profiles[dataset_name] = profiles\n",
    "    profiling_times[dataset_name] = elapsed_time\n",
    "    \n",
    "    print(f\"{dataset_name}: {len(profiles)} rules in {elapsed_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfb0018a-a5d0-4fe9-9df2-17bad0004574",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display generated profiles for each dataset\n",
    "for dataset_name, profiles in all_profiles.items():\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"{dataset_name.upper()} - {len(profiles)} Rules\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    for i, profile in enumerate(profiles, 1):\n",
    "        print(f\"{i}. {profile}\")\n",
    "    \n",
    "    print(f\"\\nSummary Stats:\")\n",
    "    print(json.dumps(all_summary_stats[dataset_name], indent=2))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data-profiler",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
